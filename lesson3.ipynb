{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21940d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install -U arxiv dotenv anthropic google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e304261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b65aaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e8a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d624a0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/llm/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2412.18022v1',\n",
       " '2406.10300v1',\n",
       " '2405.19888v1',\n",
       " '2311.10372v2',\n",
       " '2411.15764v1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4343387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "248e87bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Trustworthy and Efficient LLMs Meet Databases\",\\n  \"authors\": [\\n    \"Kyoungmin Kim\",\\n    \"Anastasia Ailamaki\"\\n  ],\\n  \"summary\": \"In the rapidly evolving AI era with large language models (LLMs) at the core,\\\\nmaking LLMs more trustworthy and efficient, especially in output generation\\\\n(inference), has gained significant attention. This is to reduce plausible but\\\\nfaulty LLM outputs (a.k.a hallucinations) and meet the highly increased\\\\ninference demands. This tutorial explores such efforts and makes them\\\\ntransparent to the database community. Understanding these efforts is essential\\\\nin harnessing LLMs in database tasks and adapting database techniques to LLMs.\\\\nFurthermore, we delve into the synergy between LLMs and databases, highlighting\\\\nnew opportunities and challenges in their intersection. This tutorial aims to\\\\nshare with database researchers and practitioners essential concepts and\\\\nstrategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining\\\\nin the intersection between LLMs and databases.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2412.18022v1\",\\n  \"published\": \"2024-12-23\"\\n}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('2412.18022v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7019d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai.types import FunctionDeclaration, Tool # These should be stable imports\n",
    "\n",
    "# Configure your API key\n",
    "genai.configure(api_key=\"<>\") # Replace with your actual API key\n",
    "\n",
    "# Your tools definition (using dictionary format for parameters, as discussed in the last successful step):\n",
    "tools = [\n",
    "    Tool(\n",
    "        function_declarations=[\n",
    "            FunctionDeclaration(\n",
    "                name=\"search_papers\",\n",
    "                description=\"Search for papers on arXiv based on a topic and store their information.\",\n",
    "                parameters={\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"topic\": {\n",
    "                            \"type\": \"STRING\",\n",
    "                            \"description\": \"The topic to search for\"\n",
    "                        },\n",
    "                        \"max_results\": {\n",
    "                            \"type\": \"INTEGER\",\n",
    "                            \"description\": \"Maximum number of results to retrieve\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"topic\"]\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    Tool(\n",
    "        function_declarations=[\n",
    "            FunctionDeclaration(\n",
    "                name=\"extract_info\",\n",
    "                description=\"Search for information about a specific paper across all topic directories.\",\n",
    "                parameters={\n",
    "                    \"type\": \"OBJECT\",\n",
    "                    \"properties\": {\n",
    "                        \"paper_id\": {\n",
    "                            \"type\": \"STRING\",\n",
    "                            \"description\": \"The ID of the paper to look for\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"paper_id\"]\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "def process_query_gemini(query, tools, execute_tool):\n",
    "    # Initialize the Gemini model with your tools\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash', tools=tools) # Or 'gemini-1.5-pro'\n",
    "\n",
    "    # Initialize message history for Gemini\n",
    "    messages = [{'role': 'user', 'parts': [{'text': query}]}] # Ensure initial message is in correct format\n",
    "\n",
    "    process_query_loop = True\n",
    "    while process_query_loop:\n",
    "        try:\n",
    "            response = model.generate_content(messages)\n",
    "\n",
    "            if response.candidates and response.candidates[0].content:\n",
    "                assistant_parts = []\n",
    "\n",
    "                for part in response.candidates[0].content.parts:\n",
    "                    if hasattr(part, 'text') and part.text: # Check for text attribute\n",
    "                        print(part.text)\n",
    "                        assistant_parts.append({'text': part.text}) # Append as dictionary if pure text\n",
    "\n",
    "                        # If it's just text, and no other parts, we might be done\n",
    "                        if len(response.candidates[0].content.parts) == 1:\n",
    "                            process_query_loop = False\n",
    "\n",
    "                    elif hasattr(part, 'function_call') and part.function_call: # Check for function_call attribute\n",
    "                        # Append the function call as a dictionary for the history\n",
    "                        assistant_parts.append({\n",
    "                            \"function_call\": {\n",
    "                                \"name\": part.function_call.name,\n",
    "                                \"args\": {k: v for k, v in part.function_call.args.items()}\n",
    "                            }\n",
    "                        })\n",
    "\n",
    "                        tool_name = part.function_call.name\n",
    "                        tool_args = {k: v for k, v in part.function_call.args.items()}\n",
    "\n",
    "                        print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "                        result = execute_tool(tool_name, tool_args)\n",
    "\n",
    "                        # Append the assistant's response (tool call) and the user's tool result to messages\n",
    "                        messages.append({'role': 'model', 'parts': assistant_parts})\n",
    "                        messages.append({\n",
    "                            'role': 'user',\n",
    "                            'parts': [{ # Use dictionary for function_response\n",
    "                                \"function_response\": {\n",
    "                                    \"name\": tool_name,\n",
    "                                    \"response\": {'result': result} # Wrap result in a dict as expected by API\n",
    "                                }\n",
    "                            }]\n",
    "                        })\n",
    "\n",
    "                        # Continue the loop to get the model's next response\n",
    "                        break # Break from the current part processing to get a new model response\n",
    "                else:\n",
    "                    # If we processed all parts and didn't break for a tool call, we might be done\n",
    "                    if not any(hasattr(p, 'function_call') for p in response.candidates[0].content.parts):\n",
    "                        process_query_loop = False\n",
    "            else:\n",
    "                print(\"No response content from Gemini.\")\n",
    "                process_query_loop = False\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during API call: {e}\")\n",
    "            process_query_loop = False\n",
    "\n",
    "# Example execute_tool (you MUST have this defined in your actual code)\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    if tool_name == \"search_papers\":\n",
    "        topic = tool_args.get(\"topic\")\n",
    "        max_results = tool_args.get(\"max_results\", 5) # Handle default here\n",
    "        if topic:\n",
    "            return f\"Successfully searched for {max_results} papers on {topic}.\"\n",
    "        else:\n",
    "            return \"Error: Topic is required for search_papers.\"\n",
    "    elif tool_name == \"extract_info\":\n",
    "        paper_id = tool_args.get(\"paper_id\")\n",
    "        if paper_id:\n",
    "            return f\"Successfully extracted information for paper ID {paper_id}.\"\n",
    "        else:\n",
    "            return \"Error: Paper ID is required for extract_info.\"\n",
    "    return f\"Unknown tool: {tool_name}\"\n",
    "\n",
    "# Example usage:\n",
    "# process_query_gemini(\"Find me 3 recent papers on large language models.\", tools, execute_tool)\n",
    "# process_query_gemini(\"Extract information for paper ID 2305.01234.\", tools, execute_tool)\n",
    "# process_query_gemini(\"Tell me a simple joke.\", tools, execute_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e41390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query_gemini(query, tools, execute_tool)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25da3ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Calling tool extract_info with args {'paper_id': '2412.18022v1'}\n",
      "OK. I've extracted the information for paper 2412.18022v1.  Do you need me to display it, or is there anything else I can help you with?\n",
      "\n",
      "\n",
      "\n",
      "Display what?  I need more information about what you want me to display.  Please provide a more specific request.\n",
      "\n",
      "\n",
      "\n",
      "Calling tool extract_info with args {'paper_id': '2412.18022v1'}\n",
      "OK. I've extracted the information for paper 2412.18022v1.  Do you want me to display it?  The response only indicates success; the actual details aren't included in the output.  I need a more sophisticated API to get the full paper details.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23fe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
